name: Update Map Snapshots (Weekly)

on:
  workflow_dispatch: {}
  schedule:
    # Weekly, Sunday 03:00 UTC
    - cron: "0 3 * * 0"

permissions:
  contents: write

concurrency:
  group: map-snapshots
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Generate snapshots
        env:
          # Use same proxy as the live site (override if needed)
          SNARC_SPARQL_ENDPOINT: https://snarc-proxy.onrender.com/query
        run: |
          node <<'NODE'
          const fs = require("fs");
          const path = require("path");

          const ENDPOINT = process.env.SNARC_SPARQL_ENDPOINT || "https://snarc-proxy.onrender.com/query";
          const OUT_DIR = path.join(process.cwd(), "data", "map-snapshots");

          if (!fs.existsSync(OUT_DIR)) fs.mkdirSync(OUT_DIR, { recursive: true });

          const langs = ["en", "cy"];

          // --- Queries (match your current MapExplorer QUERIES, but with langPref substituted) ---
          const QUERIES = {
            landforms: (langPref) => `
          PREFIX wikibase: <http://wikiba.se/ontology#>
          PREFIX wdt: <https://snarc-llgc.wikibase.cloud/prop/direct/>
          PREFIX wd: <https://snarc-llgc.wikibase.cloud/entity/>
          PREFIX bd: <http://www.bigdata.com/rdf#>
          PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>

          SELECT ?item ?itemLabel ?itemDescription ?image ?coords
                 (GROUP_CONCAT(DISTINCT ?type_label; separator=", ") AS ?types)
          WHERE {
            ?item wdt:P7/wdt:P45* wd:Q8575 .
            ?item wdt:P26 ?coords .
            ?item wdt:P7 ?type .

            ?type rdfs:label ?type_label .
            FILTER (lang(?type_label) = "${langPref}")

            OPTIONAL { ?item wdt:P31 ?image }

            SERVICE wikibase:label { bd:serviceParam wikibase:language "${langPref}". }
          }
          GROUP BY ?item ?itemLabel ?itemDescription ?image ?coords
          `.trim(),

            settlements: (langPref) => `
          PREFIX wikibase: <http://wikiba.se/ontology#>
          PREFIX wdt: <https://snarc-llgc.wikibase.cloud/prop/direct/>
          PREFIX wd: <https://snarc-llgc.wikibase.cloud/entity/>
          PREFIX bd: <http://www.bigdata.com/rdf#>
          PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>

          SELECT ?item ?itemLabel ?itemDescription ?image ?coords
                 (GROUP_CONCAT(DISTINCT ?type_label; separator=", ") AS ?types)
          WHERE {
            ?item wdt:P7/wdt:P45* wd:Q1368 .
            ?item wdt:P26 ?coords .
            ?item wdt:P7 ?type .

            ?type rdfs:label ?type_label .
            FILTER (lang(?type_label) = "${langPref}")

            OPTIONAL { ?item wdt:P31 ?image }

            SERVICE wikibase:label { bd:serviceParam wikibase:language "${langPref}". }
          }
          GROUP BY ?item ?itemLabel ?itemDescription ?image ?coords
          `.trim(),

            regions: (langPref) => `
          PREFIX wikibase: <http://wikiba.se/ontology#>
          PREFIX wdt: <https://snarc-llgc.wikibase.cloud/prop/direct/>
          PREFIX wd: <https://snarc-llgc.wikibase.cloud/entity/>
          PREFIX bd: <http://www.bigdata.com/rdf#>
          PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>

          SELECT ?item ?itemLabel ?itemDescription ?image ?coords
                 (GROUP_CONCAT(DISTINCT ?type_label; separator=", ") AS ?types)
          WHERE {
            ?item wdt:P7/wdt:P45* wd:Q8574 .
            ?item wdt:P26 ?coords .
            ?item wdt:P7 ?type .

            ?type rdfs:label ?type_label .
            FILTER (lang(?type_label) = "${langPref}")

            OPTIONAL { ?item wdt:P31 ?image }

            SERVICE wikibase:label { bd:serviceParam wikibase:language "${langPref}". }
          }
          GROUP BY ?item ?itemLabel ?itemDescription ?image ?coords
          `.trim(),

            buildings: (langPref) => `
          PREFIX wikibase: <http://wikiba.se/ontology#>
          PREFIX wdt: <https://snarc-llgc.wikibase.cloud/prop/direct/>
          PREFIX wd: <https://snarc-llgc.wikibase.cloud/entity/>
          PREFIX bd: <http://www.bigdata.com/rdf#>
          PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>

          SELECT ?item ?itemLabel ?itemDescription ?image ?coords
                 (GROUP_CONCAT(DISTINCT ?type_label; separator=", ") AS ?types)
          WHERE {
            ?item wdt:P7/wdt:P45* wd:Q9783 .
            ?item wdt:P26 ?coords .
            ?item wdt:P7 ?type .

            ?type rdfs:label ?type_label .
            FILTER (lang(?type_label) = "${langPref}")

            OPTIONAL { ?item wdt:P31 ?image }

            SERVICE wikibase:label { bd:serviceParam wikibase:language "${langPref}". }
          }
          GROUP BY ?item ?itemLabel ?itemDescription ?image ?coords
          `.trim(),
            // NOTE: peoplePlaces is generated via THREE smaller queries below (birth/death/residence)
            // and merged client-side here to reduce timeout risk.
            peoplePlaces: (langPref) => `
          PREFIX wikibase: <http://wikiba.se/ontology#>
          PREFIX wdt: <https://snarc-llgc.wikibase.cloud/prop/direct/>
          PREFIX bd: <http://www.bigdata.com/rdf#>

          SELECT ?item ?itemLabel ?itemDescription
                 ?birthplace ?deathplace ?residence
                 ?birthplacecoords ?deathplacecoords ?residencecoords
                 ?image
          WHERE {
            # Placeholder (not executed). See PEOPLE_PLACES_QUERIES + runPeoplePlaces().
            FILTER(false)
            SERVICE wikibase:label { bd:serviceParam wikibase:language "${langPref}". }
          }
          `.trim(),

            // Images layer (P50 -> IIIF handled in client; snapshot stores raw bindings)
            images: (langPref) => `
          PREFIX wikibase: <http://wikiba.se/ontology#>
          PREFIX wdt: <https://snarc-llgc.wikibase.cloud/prop/direct/>
          PREFIX bd: <http://www.bigdata.com/rdf#>

          SELECT ?item ?itemLabel ?itemDescription ?coords ?nlwmedia
          WHERE {
            ?item wdt:P26 ?coords .
            ?item wdt:P50 ?nlwmedia .

            SERVICE wikibase:label { bd:serviceParam wikibase:language "${langPref}". }
          }
          `.trim(),

            collectionsPlaces: (langPref) => `
          PREFIX wikibase: <http://wikiba.se/ontology#>
          PREFIX wdt: <https://snarc-llgc.wikibase.cloud/prop/direct/>
          PREFIX bd: <http://www.bigdata.com/rdf#>

          SELECT ?item ?itemLabel ?itemDescription ?coords
                 ?archives ?manuscripts ?clipcymru
                 ?image
          WHERE {
            { ?item wdt:P12 ?archives }
            UNION { ?item wdt:P90 ?manuscripts }
            UNION { ?item wdt:P108 ?clipcymru }

            ?item wdt:P26 ?coords .
            OPTIONAL { ?item wdt:P31 ?image }

            SERVICE wikibase:label { bd:serviceParam wikibase:language "${langPref}". }
          }
          `.trim(),

            events: (langPref) => `
          PREFIX wikibase: <http://wikiba.se/ontology#>
          PREFIX wdt: <https://snarc-llgc.wikibase.cloud/prop/direct/>
          PREFIX wd: <https://snarc-llgc.wikibase.cloud/entity/>
          PREFIX bd: <http://www.bigdata.com/rdf#>

          SELECT ?item ?itemLabel ?itemDescription ?coords ?locationLabel ?location ?image
          WHERE {
            ?item wdt:P7/wdt:P45* wd:Q9948 .
            ?item wdt:P73 ?location .
            ?location wdt:P26 ?coords .
            OPTIONAL { ?item wdt:P31 ?image }

            SERVICE wikibase:label { bd:serviceParam wikibase:language "${langPref}". }
          }
          `.trim()
  };

          // --- Split peoplePlaces into smaller queries to reduce timeouts ---
          const PEOPLE_PLACES_QUERIES = {
            birth: (langPref) => `
          PREFIX wikibase: <http://wikiba.se/ontology#>
          PREFIX wdt: <https://snarc-llgc.wikibase.cloud/prop/direct/>
          PREFIX bd: <http://www.bigdata.com/rdf#>

          SELECT ?item ?itemLabel ?itemDescription
                 ?birthplace ?birthplacecoords
                 ?image
          WHERE {
            ?item wdt:P21 ?birthplace .
           ?birthplace wdt:P26 ?birthplacecoords . 
            OPTIONAL { ?item wdt:P31 ?image }

            SERVICE wikibase:label { bd:serviceParam wikibase:language "${langPref}". }
          }
          `.trim(),

            death: (langPref) => `
          PREFIX wikibase: <http://wikiba.se/ontology#>
          PREFIX wdt: <https://snarc-llgc.wikibase.cloud/prop/direct/>
          PREFIX bd: <http://www.bigdata.com/rdf#>

          SELECT ?item ?itemLabel ?itemDescription
                 ?deathplace ?deathplacecoords
                 ?image
          WHERE {
            ?item wdt:P22 ?deathplace .
            ?deathplace wdt:P26 ?deathplacecoords .
            OPTIONAL { ?item wdt:P31 ?image }

            SERVICE wikibase:label { bd:serviceParam wikibase:language "${langPref}". }
          }
          `.trim(),

            residence: (langPref) => `
          PREFIX wikibase: <http://wikiba.se/ontology#>
          PREFIX wdt: <https://snarc-llgc.wikibase.cloud/prop/direct/>
          PREFIX bd: <http://www.bigdata.com/rdf#>

          SELECT ?item ?itemLabel ?itemDescription
                 ?residence ?residencecoords
                 ?image
          WHERE {
            ?item wdt:P78 ?residence .
            ?residence wdt:P26 ?residencecoords .
            OPTIONAL { ?item wdt:P31 ?image }

            SERVICE wikibase:label { bd:serviceParam wikibase:language "${langPref}". }
          }
          `.trim()
          };

          function mergePeoplePlaceBindings(...bindingArrays) {
            // Goal: replicate the single-query output shape (SPARQL JSON bindings),
            // while avoiding timeouts by splitting into three smaller result sets.
            //
            // Strategy:
            // - Group by item URI.
            // - Merge non-conflicting bindings into the same row.
            // - If the same item has multiple distinct values for the same field (rare but possible),
            //   create additional rows to avoid data loss.

            const byItem = new Map(); // itemUri -> [bindingRow, ...]

            const SHARED_KEYS = new Set(["item", "itemLabel", "itemDescription", "image"]);

            function canMergeRow(row, incoming) {
              for (const [k, v] of Object.entries(incoming)) {
                if (SHARED_KEYS.has(k)) continue;
                if (!row[k]) continue;
                if (row[k].value !== v.value) return false;
              }
              return true;
            }

            function mergeIntoRow(row, incoming) {
              for (const [k, v] of Object.entries(incoming)) {
                if (!row[k]) row[k] = v;
              }
              return row;
            }

            function baseFromRow(row) {
              const out = {};
              for (const k of SHARED_KEYS) {
                if (row[k]) out[k] = row[k];
              }
              return out;
            }

            for (const arr of bindingArrays) {
              for (const b of (arr || [])) {
                const itemUri = b && b.item && b.item.value;
                if (!itemUri) continue;

                const rows = byItem.get(itemUri) || [];

                // Try to merge into an existing compatible row
                let merged = false;
                for (const r of rows) {
                  if (canMergeRow(r, b)) {
                    mergeIntoRow(r, b);
                    merged = true;
                    break;
                  }
                }

                if (!merged) {
                  // Create a new row, inheriting shared fields where possible
                  const seed = rows.length ? baseFromRow(rows[0]) : {};
                  rows.push(mergeIntoRow(seed, b));
                }

                byItem.set(itemUri, rows);
              }
            }

            // Flatten to array
            const out = [];
            for (const rows of byItem.values()) out.push(...rows);
            return out;
          }


          async function fetchWithRetry(url, tries = 3) {
            let lastErr;
            for (let i = 0; i < tries; i++) {
              try {
                const controller = new AbortController();
                const timeout = setTimeout(() => controller.abort(), 120000); // 120s
                const res = await fetch(url, { method: "GET", signal: controller.signal });
                clearTimeout(timeout);

                const text = await res.text();
                if (!res.ok) throw new Error(`HTTP ${res.status}: ${text.slice(0, 300)}`);

                const json = JSON.parse(text);
                return json;
              } catch (e) {
                lastErr = e;
                const backoff = 2000 * (i + 1);
                await new Promise(r => setTimeout(r, backoff));
              }
            }
            throw lastErr;
          }

          function snapshotUrl(query) {
            return `${ENDPOINT}?query=${encodeURIComponent(query)}&format=json`;
          }

          
          async function runPeoplePlaces(langPref) {
            const qBirth = PEOPLE_PLACES_QUERIES.birth(langPref);
            const qDeath = PEOPLE_PLACES_QUERIES.death(langPref);
            const qRes = PEOPLE_PLACES_QUERIES.residence(langPref);

            const [jsonBirth, jsonDeath, jsonRes] = await Promise.all([
              fetchWithRetry(snapshotUrl(qBirth), 3),
              fetchWithRetry(snapshotUrl(qDeath), 3),
              fetchWithRetry(snapshotUrl(qRes), 3)
            ]);

            const bBirth = (jsonBirth && jsonBirth.results && jsonBirth.results.bindings) ? jsonBirth.results.bindings : [];
            const bDeath = (jsonDeath && jsonDeath.results && jsonDeath.results.bindings) ? jsonDeath.results.bindings : [];
            const bRes   = (jsonRes   && jsonRes.results   && jsonRes.results.bindings)   ? jsonRes.results.bindings   : [];

            const merged = mergePeoplePlaceBindings(bBirth, bDeath, bRes);

            const outPath = path.join(OUT_DIR, `peoplePlaces.${langPref}.json`);
            fs.writeFileSync(outPath, JSON.stringify(merged, null, 2), "utf8");
            return { datasetKey: "peoplePlaces", langPref, count: merged.length };
          }

          async function runOne(datasetKey, langPref) {
            if (datasetKey === "peoplePlaces") {
              return await runPeoplePlaces(langPref);
            }

            const q = QUERIES[datasetKey](langPref);
            const url = snapshotUrl(q);
            const json = await fetchWithRetry(url, 3);
            const bindings = (json && json.results && json.results.bindings) ? json.results.bindings : [];

            const outPath = path.join(OUT_DIR, `${datasetKey}.${langPref}.json`);
            fs.writeFileSync(outPath, JSON.stringify(bindings, null, 2), "utf8");
            return { datasetKey, langPref, count: bindings.length };
          }


          (async () => {
            const datasetKeys = Object.keys(QUERIES);
            const generatedAt = new Date().toISOString();

            const manifest = { generatedAt, endpoint: ENDPOINT, files: [] };

            // Run sequentially (most reliable for proxies). You can parallelise later.
            for (const langPref of langs) {
              for (const key of datasetKeys) {
                process.stdout.write(`Fetching ${key}.${langPref} ... `);
                const r = await runOne(key, langPref);
                console.log(`OK (${r.count})`);
                manifest.files.push(r);
              }
            }

            fs.writeFileSync(
              path.join(OUT_DIR, "index.json"),
              JSON.stringify(manifest, null, 2),
              "utf8"
            );

            console.log("Snapshots written to", OUT_DIR);
          })().catch(err => {
            console.error("Snapshot generation failed:", err);
            process.exit(1);
          });
          NODE

      - name: Commit changes (if any)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add data/map-snapshots

          # Only commit if there are changes
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "Update map snapshots (weekly)"
          git push
